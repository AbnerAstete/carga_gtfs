{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os, zipfile\n",
    "from os import remove\n",
    "import shutil\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from sqlalchemy import create_engine, desc, MetaData, func,select, text\n",
    "from sqlalchemy.orm import sessionmaker\n",
    "from models.models import Zip,Agency,Stop,Route,Stop_Times,Calendar,Trip\n",
    "from sqlalchemy.sql import exists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Nos conectamos a la base de datos\n",
    "\n",
    "### Base de datos llamada \"gtfs\"\n",
    "### En localhost\n",
    "### En el puerto 5432\n",
    "### utilizando el usaurio \"postgres\" y la contraseña \"123321\"\n",
    "\n",
    "engine = create_engine(\"postgresql://postgres:123321@localhost:5432/gtfs\")\n",
    "Session = sessionmaker(bind=engine)\n",
    "session = Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Declaramos funciones que nos ayudaran en partes especificas del proceso\n",
    "\n",
    "def actualizar_estado_mensaje(resultado, estado, mensaje):\n",
    "    resultado.estado = estado\n",
    "    resultado.mensaje = mensaje\n",
    "    session.commit()\n",
    "    \n",
    "def verificar_columnas(dataframe, columnas_necesarias, archivo):\n",
    "    columnas_sobrantes = [columna for columna in dataframe.columns if columna not in columnas_necesarias]\n",
    "    columnas_faltantes = [columna for columna in columnas_necesarias if columna not in dataframe.columns]\n",
    "\n",
    "    dataframe_filtrado = dataframe.drop(columnas_sobrantes, axis=1)\n",
    "    \n",
    "    if len(columnas_faltantes) > 0:\n",
    "        estado = \"Error\"\n",
    "        mensaje = f\"Columnas faltantes en archivo {archivo}, por favor asegúrese de que el archivo contenga las siguientes columnas: {', '.join(columnas_faltantes)}\"\n",
    "        actualizar_estado_mensaje(resultado,estado,mensaje)\n",
    "        raise ValueError(mensaje)\n",
    "    else:\n",
    "        estado = \"Procesando\"\n",
    "        mensaje = f\"Archivo '{archivo}' leído y comprobado que contenga todas las columnas necesarias, siguiendo proceso...\"\n",
    "        actualizar_estado_mensaje(resultado,estado,mensaje)\n",
    "        return dataframe_filtrado\n",
    "\n",
    "def cargar_datos(df, tabla, engine):\n",
    "    try:\n",
    "        df.to_sql(tabla, engine, if_exists='append', index=False)\n",
    "        estado = \"Procesando\"\n",
    "        mensaje = f\"Archivo '{tabla}.txt' ha sido cargado a la tabla, siguiendo proceso...\"\n",
    "        actualizar_estado_mensaje(resultado, estado, mensaje)\n",
    "\n",
    "    except Exception as e:\n",
    "        estado = \"Error\"\n",
    "        mensaje = f\"Se presentaron problemas con el Archivo '{tabla}.txt' al momento de ingresar los datos a la tabla.\"\n",
    "        actualizar_estado_mensaje(resultado, estado, mensaje)\n",
    "\n",
    "def eliminar_registros_antiguos(session, df_db, df,modelo,tabla):\n",
    "    try:\n",
    "        comparar = df_db.merge(df, indicator=True, how='outer')\n",
    "        registros_antiguos = comparar.loc[lambda x: x['_merge'] == 'left_only'].drop(columns='_merge')\n",
    "        for i, row in registros_antiguos.iterrows():\n",
    "            session.query(modelo).filter_by(**{modelo.__table__.primary_key.columns.keys()[0]: row[0]}).delete()\n",
    "            session.commit()\n",
    "\n",
    "        estado = \"Procesando\"\n",
    "        mensaje = f\"Se eliminaron los registros obsoletos, no se encontraban en el dataframe '{tabla}' entrante.\"\n",
    "        actualizar_estado_mensaje(resultado, estado, mensaje)\n",
    "\n",
    "    except Exception as e:\n",
    "        estado = \"Error\"\n",
    "        mensaje = f\"Se presentaron problemas con el al momento de eliminar los registros que no se encontraban en el'{tabla}' entrante.\"\n",
    "        actualizar_estado_mensaje(resultado, estado, mensaje)\n",
    "    \n",
    "\n",
    "def agregar_registros_nuevos(df_db, df, tabla, engine):\n",
    "    try:\n",
    "        comparar = df_db.merge(df, indicator=True, how='outer')\n",
    "        diferencias = comparar.loc[lambda x: x['_merge'] == 'right_only'].drop(columns='_merge')\n",
    "        diferencias.to_sql(tabla, engine, if_exists='append', index=False)\n",
    "\n",
    "        estado = \"Procesando\"\n",
    "        mensaje = f\"Se agregaron los registros nuevos en la tabla de '{tabla}'.\"\n",
    "        actualizar_estado_mensaje(resultado, estado, mensaje)\n",
    "\n",
    "    except Exception as e:\n",
    "        estado = \"Error\"\n",
    "        mensaje = f\"Se presentaron problemas con el al momento de agregar registros nuevos en la tabla de '{tabla}'.\"\n",
    "        actualizar_estado_mensaje(resultado, estado, mensaje)\n",
    "\n",
    "def verificar_base_de_datos_vacia(session):\n",
    "   \n",
    "    # Verificar si las tablas tiene al menos un registro\n",
    "    tiene_registros_agency = session.query(exists().select_from(Agency)).scalar()\n",
    "    tiene_registros_route = session.query(exists().select_from(Route)).scalar()\n",
    "    tiene_registros_calendar = session.query(exists().select_from(Calendar)).scalar()\n",
    "    tiene_registros_stop = session.query(exists().select_from(Stop)).scalar()\n",
    "    tiene_registros_trip = session.query(exists().select_from(Trip)).scalar()\n",
    "    tiene_registros_stop_times = session.query(exists().select_from(Stop_Times)).scalar()\n",
    "\n",
    "    # Verificar si la base de datos tiene datos\n",
    "    base_de_datos_vacia = (\n",
    "        not tiene_registros_agency and\n",
    "        not tiene_registros_route and\n",
    "        not tiene_registros_calendar and\n",
    "        not tiene_registros_stop and\n",
    "        not tiene_registros_trip and\n",
    "        not tiene_registros_stop_times\n",
    "    )\n",
    "    \n",
    "    return base_de_datos_vacia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Seleccionamos el ultimo zip que fue subido, recolectamos los datos del zip y notificamos a la bd en que parte del proceso estamos\n",
    "\n",
    "resultado = session.query(Zip).order_by(desc('fecha')).first()\n",
    "id_zip = resultado.id_transaccion\n",
    "nombre_zip = resultado.nombre_zip\n",
    "fecha_zip = resultado.fecha\n",
    "\n",
    "estado = \"Procesando\"\n",
    "mensaje = \"Recolectando datos del ultimo archivo ZIP ingresado.\"\n",
    "actualizar_estado_mensaje(resultado,estado,mensaje)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extraigo todo los archivos txt del ultimo ZIP que se ingreso\n",
    "ruta = 'zips/'\n",
    "ruta_zip = ruta + nombre_zip + \".zip\"\n",
    "\n",
    "with zipfile.ZipFile(ruta_zip, 'r') as archivo_zip:\n",
    "    archivo_zip.extractall('txts/')\n",
    "\n",
    "estado = \"Procesando\"\n",
    "mensaje = \"Extrayendo archivos del ultimo ZIP ingresado.\"\n",
    "actualizar_estado_mensaje(resultado,estado,mensaje)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variables que me ayudaran a inspeccionar los elementos dentro del ZIP\n",
    "ruta_txt = 'txts/'\n",
    "archivos_en_txt = os.listdir(ruta_txt)\n",
    "\n",
    "#Se especifican los archivos que son necesarios\n",
    "archivos_esperados = ['agency.txt','calendar.txt','routes.txt','stop_times.txt','stops.txt','trips.txt']\n",
    "archivos_faltantes = []\n",
    "\n",
    "# Inspecciono si tengo todos los archivos esperados\n",
    "for archivo in archivos_esperados:\n",
    "    if archivo not in archivos_en_txt:\n",
    "        archivos_faltantes.append(archivo)\n",
    "\n",
    "# Este condicional dara verdadero si no se tienen los archivos esperados/necesarios.\n",
    "if len(archivos_faltantes) > 0:\n",
    "\n",
    "    #Se actualiza el estado y el mensaje en la BD.\n",
    "    estado = \"Error\"\n",
    "    mensaje = \"Archivos Faltantes, por favor ingrese los siguientes archivos: \"+\",\".join(archivos_faltantes)\n",
    "    actualizar_estado_mensaje(resultado,estado,mensaje)\n",
    "\n",
    "    # Si el ZIP no tiene los archivos esperados se elimina del directorio.\n",
    "    remove(ruta_zip)\n",
    "    # Se eliminan los archivos txts.\n",
    "    shutil.rmtree(ruta)\n",
    "    # Controlamos la excepcion\n",
    "    raise ValueError(mensaje)\n",
    "\n",
    "\n",
    "# Se actualiza el estado del procesamineto del archivo en la BD.\n",
    "estado = \"Procesando\"\n",
    "mensaje = \"Total de archivos esperados, siguiendo proceso...\"\n",
    "actualizar_estado_mensaje(resultado,estado,mensaje)\n",
    "\n",
    "# Eliminamos los archivos sobrantes en la ruta txt\n",
    "for archivo in archivos_en_txt:\n",
    "    if archivo not in archivos_esperados:\n",
    "        os.remove(ruta_txt+archivo)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Leer archivos con PANDAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Leemos el archivo agency.txt, lo guardamos en un dataframe, comprobamos que tenga las columnas necesarias y actualizamos la BD\n",
    "try:\n",
    "    df_agency = pd.read_csv('txts/agency.txt', dtype=str)\n",
    "except Exception as e:\n",
    "        estado = \"Error\"\n",
    "        mensaje = \"Se presentaron problemas al momento de transformar el archivo agency.txt a dataframe\"\n",
    "        actualizar_estado_mensaje(resultado, estado, mensaje)\n",
    "columnas_necesarias_agency = ['agency_id','agency_name','agency_url','agency_timezone','agency_lang','agency_phone','agency_fare_url']\n",
    "df_agency = verificar_columnas(df_agency, columnas_necesarias_agency, 'agency.txt')\n",
    "\n",
    "#Leemos el archivo calendar.txt , lo guardamos en un dataframe y actualizamos la BD\n",
    "try:\n",
    "    df_calendar = pd.read_csv('txts/calendar.txt', dtype=str)\n",
    "except Exception as e:\n",
    "        estado = \"Error\"\n",
    "        mensaje = \"Se presentaron problemas al momento de transformar el archivo calendar.txt a dataframe\"\n",
    "        actualizar_estado_mensaje(resultado, estado, mensaje)\n",
    "columnas_necesarias_calendar = ['service_id','start_date','end_date','monday','tuesday','wednesday','thursday','friday','saturday','sunday']\n",
    "df_calendar = verificar_columnas(df_calendar, columnas_necesarias_calendar, 'calendar.txt')\n",
    "\n",
    "#Leemos el archivo routes.txt , lo guardamos en un dataframe y actualizamos la BD\n",
    "try:\n",
    "    df_routes = pd.read_csv('txts/routes.txt', dtype=str)\n",
    "except Exception as e:\n",
    "        estado = \"Error\"\n",
    "        mensaje = \"Se presentaron problemas al momento de transformar el archivo routes.txt a dataframe\"\n",
    "        actualizar_estado_mensaje(resultado, estado, mensaje)\n",
    "columnas_necesarias_route = ['route_id','agency_id','route_short_name','route_long_name','route_desc','route_type','route_url','route_color','route_text_color']\n",
    "df_routes = verificar_columnas(df_routes, columnas_necesarias_route, 'routes.txt')\n",
    "\n",
    "#Leemos el archivo stop_times.txt , lo guardamos en un dataframe y actualizamos la BD\n",
    "try:\n",
    "    df_stop_times = pd.read_csv('txts/stop_times.txt', dtype=str)\n",
    "except Exception as e:\n",
    "        estado = \"Error\"\n",
    "        mensaje = \"Se presentaron problemas al momento de transformar el archivo stop_times.txt a dataframe\"\n",
    "        actualizar_estado_mensaje(resultado, estado, mensaje)\n",
    "columnas_necesarias_stop_times = ['trip_id','arrival_time','departure_time','stop_id','stop_sequence','stop_headsign','pickup_type','drop_off_type','timepoint']\n",
    "df_stop_times = verificar_columnas(df_stop_times, columnas_necesarias_stop_times, 'stop_times.txt')\n",
    "\n",
    "#Leemos el archivo stops.txt , lo guardamos en un dataframe y actualizamos la BD\n",
    "try:\n",
    "    df_stops = pd.read_csv('txts/stops.txt', dtype=str)\n",
    "except Exception as e:\n",
    "        estado = \"Error\"\n",
    "        mensaje = \"Se presentaron problemas al momento de transformar el archivo stops.txt a dataframe\"\n",
    "        actualizar_estado_mensaje(resultado, estado, mensaje)\n",
    "columnas_necesarias_stops = ['stop_id','stop_code','stop_name','stop_desc','stop_lat','stop_lon','zone_id','stop_url','location_type','parent_station','wheelchair_boarding']\n",
    "df_stops = verificar_columnas(df_stops, columnas_necesarias_stops, 'stops.txt')\n",
    "\n",
    "#Leemos el archivo trips.txt , lo guardamos en un dataframe y actualizamos la BD\n",
    "try:\n",
    "    df_trips = pd.read_csv('txts/trips.txt', dtype=str)\n",
    "except Exception as e:\n",
    "        estado = \"Error\"\n",
    "        mensaje = \"Se presentaron problemas al momento de transformar el archivo trips.txt a dataframe\"\n",
    "        actualizar_estado_mensaje(resultado, estado, mensaje)\n",
    "columnas_necesarias_trips = ['route_id','service_id','trip_id','trip_headsign','trip_short_name','direction_id','block_id','shape_id','wheelchair_accessible','bikes_allowed']\n",
    "df_trips = verificar_columnas(df_trips, columnas_necesarias_trips, 'trips.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "if verificar_base_de_datos_vacia(session):\n",
    "\n",
    "    cargar_datos(df_agency, 'Agency', engine)\n",
    "    cargar_datos(df_routes, 'Route', engine)\n",
    "    cargar_datos(df_calendar, 'Calendar', engine)\n",
    "    cargar_datos(df_stops, 'Stop', engine)\n",
    "    cargar_datos(df_trips, 'Trip', engine)\n",
    "    cargar_datos(df_stop_times, 'Stop_Times', engine)\n",
    "    \n",
    "else:\n",
    "    \n",
    "    with engine.connect() as connection:\n",
    "        df_db_agency = pd.read_sql_table('Agency', con=connection)\n",
    "        df_db_routes = pd.read_sql_table('Route', con=connection)\n",
    "        df_db_calendar = pd.read_sql_table('Calendar', con=connection)\n",
    "        df_db_stops = pd.read_sql_table('Stop', con=connection)\n",
    "        df_db_trips = pd.read_sql_table('Trip', con=connection)\n",
    "        df_db_stop_times = pd.read_sql_table('Stop_Times', con=connection)\n",
    "\n",
    "    eliminar_registros_antiguos(session, df_db_stop_times, df_db_stop_times, Stop_Times,'Stop_Times')\n",
    "    eliminar_registros_antiguos(session, df_db_trips, df_trips, Trip,'Trip')\n",
    "    eliminar_registros_antiguos(session, df_db_routes, df_routes, Route,'Route')\n",
    "    eliminar_registros_antiguos(session, df_db_agency, df_agency, Agency,'Agency')\n",
    "    eliminar_registros_antiguos(session, df_db_calendar, df_calendar, Calendar,'Calendar')\n",
    "    eliminar_registros_antiguos(session, df_db_stops, df_stops, Stop, 'Stop')\n",
    "    \n",
    "    agregar_registros_nuevos(df_db_agency, df_agency, 'Agency', engine)\n",
    "    agregar_registros_nuevos(df_db_routes, df_routes, 'Route', engine)\n",
    "    agregar_registros_nuevos(df_db_calendar, df_calendar, 'Calendar', engine)\n",
    "    agregar_registros_nuevos(df_db_stops, df_stops, 'Stop', engine)\n",
    "    agregar_registros_nuevos(df_db_trips, df_trips, 'Trip', engine)\n",
    "    agregar_registros_nuevos(df_db_stop_times, df_stop_times, 'Stop_Times', engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creo un nuevo archivo ZIP filtrado con los datos esperados/necesarios y generar un nuevo estandar de archivos gtfs\n",
    "shutil.make_archive('zips_procesados/'+nombre_zip+'_procesado','zip','txts')\n",
    "estado = \"Procesando\"\n",
    "mensaje = \"Nuevo archivo ZIP generado, contiene unicamente archivos esperados\"\n",
    "actualizar_estado_mensaje(resultado,estado,mensaje)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
